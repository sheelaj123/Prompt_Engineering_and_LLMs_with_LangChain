{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM3U9fMy75oCFhhPf9FRLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheelaj123/Prompt_Engineering_and_LLMs_with_LangChain/blob/main/Sequential_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ho7qZmZVAlOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color =red>Sequential Prompting :\n",
        "\n",
        "##IN Simple chain-  we can take only 1 input.\n",
        "\n",
        "##whereas in sequential chain, we can take more than 1 input.\n",
        "\n",
        "###Sequentially by considering more than one input and produce more than one output. Then, we cannot use simpleSequential() Prompt, instead we go for Sequential Prompt.\n",
        "\n",
        "\n",
        "Let's understand with examples --"
      ],
      "metadata": {
        "id": "yTKHLSVCAp--"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4LvObIM2MSH",
        "outputId": "e8be2cfa-f3c3-4cdf-9618-c272bbff7be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/806.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/806.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/806.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain)\n",
            "  Downloading langchain_community-0.0.18-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.19-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.5/238.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.86-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.18 langchain-core-0.1.19 langsmith-0.0.86 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8KII3Zw2RQB",
        "outputId": "3ce60851-8e0b-46fa-a7ed-a9ebc98a5d24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "#place your Huggingface API key after running this cell\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfuabL912UwQ",
        "outputId": "00fcaf23-43fb-4775-bf58-62ab83076f75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import HuggingFaceHub\n",
        "model = \"google/flan-t5-xxl\"\n"
      ],
      "metadata": {
        "id": "9lA7ZVqr2Vku"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "llm1 = HuggingFaceHub(repo_id=model, model_kwargs={\"temperature\":0.6, \"max_length\":100})\n",
        "# An LLMChain to write a a short note about a bird given a title of the bird and the color.\n",
        "template = \"\"\"You are a writer. Given the name of the bird and the color of it, it is your job to write a brief note about the bird.\n",
        "           Name: {name}Color: {color} Note: This is a brief note about the above mentioned bird:\"\"\"\n",
        "#prompt with 2 inputs\n",
        "prompt_template = PromptTemplate(input_variables=[\"name\", \"color\"], template=template)\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt_template, output_key=\"summary\")\n",
        "print(chain1.run({\"name\":\"Bird\", \"color\": \"Green\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJMhOJrD2Zhq",
        "outputId": "dc1cdea3-a3e9-46f2-a2d9-e9e3aa168b83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bird is green.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = HuggingFaceHub(repo_id=model, model_kwargs={\"temperature\":0.6, \"max_length\":64})\n",
        "template = \"\"\"You are a reviewer of the content. Given the summary about a bird, it is your job to write a review for that summary.\n",
        "              Bird Summary:{summary} Review of summary:\"\"\"\n",
        "#Prompt with 1 input\n",
        "prompt_template = PromptTemplate(input_variables=[\"summary\"], template=template)\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt_template, output_key=\"review\")\n"
      ],
      "metadata": {
        "id": "e6nhpdBN2aen"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the overall chain where we run these two chains in sequence.\n",
        "from langchain.chains import SequentialChain\n",
        "#combining 2 prompts sequentially to produce 2 outputs\n",
        "overall_chain = SequentialChain(chains=[chain1, chain2],input_variables=[\"name\", \"color\"],output_variables=[\"summary\", \"review\"],verbose=True)\n"
      ],
      "metadata": {
        "id": "QdX-NM3n2eBd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain({\"name\":\"Bird\", \"color\": \"Green\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCJuOwCl2hI_",
        "outputId": "9acc4332-94f8-49f6-e0ef-a60b525b3702"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Bird',\n",
              " 'color': 'Green',\n",
              " 'summary': 'The bird is green.',\n",
              " 'review': 'The bird is green.'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Let's see Another example ==>\n",
        "\n",
        "###I'm taking  \"meta-llama/Llama-2-7b-chat-hf\"  model from Hugging-face,\n",
        " length : 120"
      ],
      "metadata": {
        "id": "vHLp_GO32jdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = \"google/flan-t5-xxl\""
      ],
      "metadata": {
        "id": "l4OEvQcZ2kbW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm3 = HuggingFaceHub(repo_id=my_model, model_kwargs={\"temperature\":0.6, \"max_length\":160})\n",
        "# # An LLMChain to write a a short note about a fruit given a title of the  fruit and the color and origin of that fruit.\n",
        "# template3 =\"\"\"You are a text generator. Given the name of the fruit and  color , it is your job to generate brief and detailed summary about the Fruit  :{name} , Color:{color}, FruitOrigin :{origin} of that fruit.\"\"\"\n",
        "# #prompt with 3 inputs\n",
        "# prompt_template3 = PromptTemplate(input_variables=[\"name\", \"color\", \"origin\" ], template=template3)\n",
        "# chain3 = LLMChain(llm=llm3, prompt=prompt_template3, output_key=\"summary\")\n",
        "# print(chain3.run({\"name\":\"fruit\", \"color\": \"red\",\"FruitOrigin\":\"origin\"}))\n",
        "# # template3 =\"\"\"You are a text generator. Given the name of the fruit and  color , it is your job to generate brief and detailed summary about the Fruit  :{name} , Color:{color}, FruitOrigin :{fruitorigin} of that fruit. \\n Note: {summary}This is a brief note about the above mentioned fruit \"\"\"\n",
        "\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "llm3 = HuggingFaceHub(repo_id=model, model_kwargs={\"temperature\":0.6, \"max_length\":100})\n",
        "\n",
        "# An LLMChain to write a a short note about fruit given a title of the fruit and the origin of fruit.\n",
        "template3 = \"\"\"You are a content generator. Given the name of the fruit and the color of it as well as origin of fruits,\n",
        "           Name: {name} Color: {color} origin:{origin}\"\"\"\n",
        "\n",
        "#prompt with 3 inputs\n",
        "prompt_template3 = PromptTemplate(input_variables=[\"name\", \"color\",\"origin\"], template=template3)\n",
        "chain3 = LLMChain(llm=llm3, prompt=prompt_template3, output_key=\"summary\")\n",
        "print(chain3.run({\"name\":\"fruit\", \"color\": \"orange\",\"origin\":\"japan\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsBEtgB32n7p",
        "outputId": "d0b6b57c-1c42-4f10-8d43-176a9bbb682c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm4 = HuggingFaceHub(repo_id=my_model, model_kwargs={\"temperature\":0.6, \"max_length\":64})\n",
        "template4 = \"\"\"You are a reviewer of the content. Given the summary about a fruit.\n",
        "              Fruit Summary:{summary}\"\"\"\n",
        "#Prompt with 1 input\n",
        "prompt_template4 = PromptTemplate(input_variables=[\"summary\"], template=template4)\n",
        "chain4 = LLMChain(llm=llm4, prompt=prompt_template4)\n"
      ],
      "metadata": {
        "id": "cX3tnJJC2shm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the overall chain where we run these two chains in sequence.\n",
        "from langchain.chains import SequentialChain\n",
        "#combining 2 prompts sequentially to produce 2 outputs\n",
        "overall_chain5 = SequentialChain(chains=[chain3, chain4],input_variables=[\"name\", \"color\",\"origin\"],output_variables=[\"summary\"],verbose=True)\n"
      ],
      "metadata": {
        "id": "5oRF4FaR8uGU"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain5({\"name\":\"fruit\", \"color\": \"red\",\"origin\":\"India\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAHe4RUh9IeR",
        "outputId": "f4ed1d23-19af-4496-d615-55ad281106ba"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'fruit',\n",
              " 'color': 'red',\n",
              " 'origin': 'India',\n",
              " 'summary': 'fruit is a red fruit with white flesh from India.'}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##topic ends here, thanks for visiting...<>"
      ],
      "metadata": {
        "id": "ltAOBJghAeEF"
      }
    }
  ]
}